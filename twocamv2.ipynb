{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede363e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary libraries\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2\n",
    "import os\n",
    "import traceback\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88328087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an HandLandmarker object.\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# Create a hand landmarker instance with the image mode:\n",
    "hand_landmarker_options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='models/hand_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    "    num_hands=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3462590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an ObjectDetector object.\n",
    "ObjectDetector = mp.tasks.vision.ObjectDetector\n",
    "ObjectDetectorOptions = mp.tasks.vision.ObjectDetectorOptions\n",
    "\n",
    "\n",
    "detector_options = ObjectDetectorOptions(\n",
    "    base_options=BaseOptions(model_asset_path='models/ssd_mobilenet_v2.tflite'),\n",
    "    score_threshold=0.5,\n",
    "    max_results=3,\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    "    category_denylist=[\"person\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12dafe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "landmarker = HandLandmarker.create_from_options(hand_landmarker_options) \n",
    "detector = vision.ObjectDetector.create_from_options(detector_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00b88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onlaweng_utils import draw_bounding_boxes, draw_landmarks, draw_detection_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0fc20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 640\n",
    "HEIGHT = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e620195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_pt_distance(pt1, pt2):\n",
    "    x1, y1 = pt1\n",
    "    x2, y2 = pt2\n",
    "    distance = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    return distance\n",
    "\n",
    "import math\n",
    "class Line2D :\n",
    "    def __init__(self, p1, p2) :\n",
    "        dx = p2[0] - p1[0]\n",
    "        dy = p2[1] - p1[1]\n",
    "        m = dy / (dx if dx != 0 else 0.000001)\n",
    "        m = m if m != 0 else 0.000001\n",
    "        c = p1[1] - (m * p1[0])\n",
    "        \n",
    "        self.x_top_intercept = round(-c/m)\n",
    "        self.x_bot_intercept = round((HEIGHT - c)/m)\n",
    "        self.y_left_intercept = round(c)\n",
    "        self.y_right_intercept = round((m * WIDTH) + c)\n",
    "        \n",
    "        self.m = m\n",
    "        self.c = c\n",
    "        \n",
    "    # draw lines from given point to each intercepts\n",
    "    def draw_intercept(self, image, pt) :\n",
    "        h, w, _ =  image.shape\n",
    "        if self.x_top_intercept >= 0 and self.x_top_intercept < w :\n",
    "            cv2.line(image, pt, (self.x_top_intercept, 0), (0,222,0), 1)\n",
    "        if self.x_bot_intercept >= 0 and self.x_bot_intercept < w :\n",
    "            cv2.line(image, pt, (self.x_bot_intercept, h), (0,222,0), 1)\n",
    "        if self.y_left_intercept >= 0 and self.y_left_intercept < h :\n",
    "            cv2.line(image, pt, (0, self.y_left_intercept), (0,222,0), 1)\n",
    "        if self.y_right_intercept >= 0 and self.y_right_intercept < h :\n",
    "            cv2.line(image, pt, (w, self.y_right_intercept), (0,222,0), 1)\n",
    "    \n",
    "    # calculate distance between given point and this line\n",
    "    def pt_distance(self, pt) :    \n",
    "        A = self.m\n",
    "        B = -1\n",
    "        C = self.c\n",
    "        \n",
    "        return math.fabs((A * pt[0]) + (B * pt[1]) + C) / math.sqrt((A**2) + (B**2))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c8829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    image = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "    pointedObject = []\n",
    "    \n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    mp_img = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "    \n",
    "    # detect hands and objects\n",
    "    detector_results = detector.detect(mp_img)\n",
    "    hand_results = landmarker.detect(mp_img)\n",
    "    \n",
    "    # # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    #print(results)\n",
    "    try :\n",
    "        if hand_results.hand_landmarks and hand_results.handedness[0][0].category_name == 'Right':\n",
    "            tip_landmark = hand_results.hand_landmarks[0][8]\n",
    "            dip_landmark = hand_results.hand_landmarks[0][7]\n",
    "            tip_landmark = (round(tip_landmark.x * WIDTH), round(tip_landmark.y * HEIGHT))\n",
    "            dip_landmark = (round(dip_landmark.x * WIDTH), round(dip_landmark.y * HEIGHT))\n",
    "            \n",
    "            l = Line2D(tip_landmark, dip_landmark)\n",
    "            l.draw_intercept(image, tip_landmark)\n",
    "            \n",
    "            draw_landmarks(image, hand_results.hand_landmarks[0], mp.solutions.hands.HAND_CONNECTIONS)\n",
    "        \n",
    "            pointing_threshold = 100\n",
    "            if detector_results :\n",
    "                for idx, detection in enumerate(detector_results.detections) :\n",
    "                    bbox = detection.bounding_box\n",
    "                    centroid_x = bbox.origin_x + (bbox.width // 2)\n",
    "                    centroid_y = bbox.origin_y + (bbox.height // 2)\n",
    "                    centroid = (centroid_x, centroid_y)\n",
    "                    \n",
    "                    if l.pt_distance(centroid) <= pointing_threshold and pt_pt_distance(centroid, dip_landmark) > pt_pt_distance(centroid, tip_landmark) :\n",
    "                        label = sorted([(c.category_name, round(c.score, 2)) for c in detection.categories])[0]\n",
    "                        label = label[0]\n",
    "                        acc = label[1]\n",
    "                        \n",
    "                        # pointed object returns label, accuracy, and bounding box\n",
    "                        pointedObject.append({\n",
    "                            \"label\": label,\n",
    "                            \"acc\": acc, \n",
    "                            \"bbox\": bbox,\n",
    "                        })\n",
    "                        cv2.circle(image, centroid, 10, (0, 255, 0), 2)\n",
    "                        \n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        return None, pointedObject\n",
    "    \n",
    "    return image, pointedObject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fe6b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap1 = cv2.VideoCapture(0)\n",
    "cap2 = cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b166369",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap1.isOpened() and cap2.isOpened():\n",
    "    success1, image1 = cap1.read()\n",
    "    success2, image2 = cap2.read()\n",
    "    \n",
    "    res_image = cv2.flip(image1.copy(), 1)\n",
    "    \n",
    "    if not success1 or not success2 :\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "    try:\n",
    "        image1, pointedObject1 = process_image(image1)\n",
    "        image2, pointedObject2 = process_image(image2)\n",
    "        \n",
    "        for idx, obj in enumerate(pointedObject1) :\n",
    "            if obj[\"label\"] in [obj2[\"label\"] for obj2 in pointedObject2] :\n",
    "                draw_detection_box(res_image,  obj[\"bbox\"], obj[\"label\"], obj[\"acc\"], 2023+idx)\n",
    "        \n",
    "        cv2.imshow('MediaPipe Object Detection With 2 Cameras', np.hstack((image1, image2)))\n",
    "        cv2.imshow('resullt', res_image)\n",
    "    \n",
    "    except Exception as e :\n",
    "        print(traceback.format_exc())\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(5) == ord('q'):\n",
    "        break\n",
    "\n",
    "# cap1.release()\n",
    "# cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc586cd",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
